{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aditi_Chouhan_200040_Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Aim**  \n",
        "The motive of this assignment is to make predictions using **Linear Regression**. To make sure you truly understand how the underlying algorithm works, you are to implement it from scratch."
      ],
      "metadata": {
        "id": "RB2d1J1f1CF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the dataset  \n",
        "Run the cell below to create the dataset. It further splits the available data into training and testing. Please do not edit this cell.\n"
      ],
      "metadata": {
        "id": "a_S80lf6H4Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate the data\n",
        "X, y = datasets.make_regression(n_samples=100, n_features=5, noise=20, random_state=4)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "yX0zqXcHIQHP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the data  \n",
        "Use `matplotlib` to visualize the given data."
      ],
      "metadata": {
        "id": "Zj4rrRXGJBXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrKv1oIVpQNj",
        "outputId": "9d1e1b34-0e53-496e-af6b-5bb3e74245a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(5,1,1)\n",
        "plt.scatter(X[:,0],y)\n",
        "plt.title(\"Feature 1\")\n",
        "\n",
        "plt.subplot(5,1,2)\n",
        "plt.scatter(X[:,1],y)\n",
        "plt.title(\"Feature 2\")\n",
        "\n",
        "plt.subplot(5,1,3)\n",
        "plt.scatter(X[:,2],y)\n",
        "plt.title(\"Feature 3\")\n",
        "\n",
        "plt.subplot(5,1,4)\n",
        "plt.scatter(X[:,3],y)\n",
        "plt.title(\"Feature 4\")\n",
        "\n",
        "plt.subplot(5,1,5)\n",
        "plt.scatter(X[:,4],y)\n",
        "plt.title(\"Feature 5\")\n",
        "\n",
        "plt.show()\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "zxfi8dkBJOUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "600b2864-4248-4f3c-929f-8a3e646b3433"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should be able to see the linear relations between `y` and the features in vector `X`."
      ],
      "metadata": {
        "id": "r7vndSBAJceF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent Review  \n",
        "1. ####  Cost function\n",
        "Define the `cost function` to measure the difference between predictions and target outputs. Here, we are working with first degree polynomial, so derivatives are easy to calculate. ( Linear function `y = wx +b` )  \n",
        "\n",
        "$$Error = \\frac{1}{N}\\sum_{i=1}^N (y_i - \\overline{y}_i)^2 = \\frac{1}{N}\\sum_{i=1}^N (y_i - (x_iw+b))^2 $$  \n",
        "\n",
        "  where `N` is the number of samples  \n",
        "    \n",
        "\n",
        "\n",
        "2. #### Compute the derivative\n",
        "$$\\frac{\\delta Error}{\\delta w} = \\frac{2}{N}\\sum_{i=1}^N -x_i(y_i -(m  x_i +b ))  $$\n",
        "$$\\frac{\\delta Error}{\\delta b} = \\frac{2}{N}\\sum_{i=1}^N -(y_i -(m  x_i +b ))  $$\n",
        "3. <h4>Update current parameters</h4>\n",
        "$$ w:= w- learning\\_rate \\cdot \\frac{\\delta Error}{\\delta w}   $$ \n",
        "$$ b:= b- learning\\_rate \\cdot \\frac{\\delta Error}{\\delta b}   $$ \n",
        "4. <h4>Repeat until it fits good enough</h4>\n"
      ],
      "metadata": {
        "id": "b4I9Z3epNvBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition\n",
        "\n",
        "Complete the functions in the class below. Hints provided at appropriate places."
      ],
      "metadata": {
        "id": "kBtUcOVnJu-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "\n",
        "    # The __init__ is called when we make any object of our class. Here, you are to specify the default values for \n",
        "    # Learning Rate, Number of Iterations, Weights and Biases. It doesn't return anything.\n",
        "    # Hint: Google what a `self pointer` is and figure out how it can be used here.\n",
        "    def __init__(self, learning_rate=0.01, n_iters=10000):\n",
        "        # Your code here\n",
        "        self.learn = learning_rate;\n",
        "        self.iter = n_iters;\n",
        "        self.w = np.random.random(X_train.shape[1]);\n",
        "        self.b = 0;\n",
        "        \n",
        "        # pass  # Uncomment this when you're done with this function\n",
        "\n",
        "\n",
        "    # The following function would be the heart of the model. This is where the training would happen. \n",
        "    # You're supposed to iterate and keep on updating the weights and biases according to the steps of Gradient Descent.\n",
        "    def fit(self, X, y):\n",
        "        # Gradient Descent code goes here\n",
        "        N = X.shape[0]\n",
        "        # print(N)\n",
        "        # print(np.square(y-(np.dot(X,self.w)+self.b).reshape(-1,1)))\n",
        "        cost = (1/N)*np.sum(np.square(y-(np.dot(X,self.w)+self.b).reshape(-1,1)),axis=0);\n",
        "        # print(cost);\n",
        "        # print(-X*np.square((y-(np.dot(X,self.w)+self.b)))[:,None])\n",
        "        for i in range(self.iter) :\n",
        "          dw = (2/N)*np.sum(-1*X*(y-(np.dot(X,self.w)+self.b).reshape(-1,1)), axis=0);\n",
        "          db = (2/N)*np.sum(-y+((np.dot(X,self.w)+self.b).reshape(-1,1)), axis=0);\n",
        "          self.w = self.w-self.learn*dw\n",
        "          self.b = self.b-self.learn*db\n",
        "        \n",
        "        # print(self.w)\n",
        "        # print(self.b)\n",
        "        # print(cost)\n",
        "        # pass  # Uncomment this when you're done with this function\n",
        "        \n",
        "        \n",
        "    # This function will be called after our model has been trained and we are predicting on unseen data\n",
        "    # What is our prediction? Just return that\n",
        "    def predict(self, X):\n",
        "        # Code goes her\n",
        "        return np.dot(X,self.w)+self.b\n",
        "        # pass  # Uncomment this when you're done with this function"
      ],
      "metadata": {
        "id": "dGnFNPJx3I28"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing, Training & Predictions"
      ],
      "metadata": {
        "id": "EvyInkTKPn7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we make an object of our custom class.\n",
        "regressor = LinearRegression() # You may pass the custom parameters or let the default values take it ahead\n",
        "\n",
        "# Call the fit method on the object to train (pass appropriate part of dataset)\n",
        "# print(np.dot(X_train,regressor.w))\n",
        "# y_train = y_train[:]\n",
        "y_train = y_train.reshape(-1,1);\n",
        "# print(y_train.shape)\n",
        "regressor.fit(X_train,y_train)\n",
        "\n",
        "# Now, let's see our what our model predicts\n",
        "predictions = regressor.predict(X_test) # pass appropriate part of dataset"
      ],
      "metadata": {
        "id": "nvItUpAkHTiv"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_kbHnBV24_u",
        "outputId": "d60b7bcd-537a-491f-f4a8-ecb424c5aa54"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 207.90288602, -123.30753064,   78.36331292, -144.89131576,\n",
              "          0.59146132,  -61.4096294 ,   42.99351375,   23.13379989,\n",
              "       -134.95991245,  143.72552576,   76.94489743,  123.3435483 ,\n",
              "         34.00548086,   90.25352353,   58.96486393,   86.1167232 ,\n",
              "        201.84413768,   68.22770101,   95.03409129,  -65.65839881])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkZ2gsTK4GeZ",
        "outputId": "9726cb2a-b8ec-49de-9ab6-7036027ddd86"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 231.52987097, -127.73130463,   82.03512178, -114.56084875,\n",
              "        -40.94506552,  -46.3723945 ,   17.14558018,   36.59841286,\n",
              "       -144.50935547,  172.29644855,   52.02363624,  150.91337265,\n",
              "         24.4817991 ,   77.51790564,   62.62990566,   76.3859825 ,\n",
              "        195.3197199 ,   47.75398372,   78.13610249,  -76.28526953])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model   \n",
        "\n",
        "Return [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) & [R2 Score](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html#:~:text=%C2%AFy) from the functions below."
      ],
      "metadata": {
        "id": "tzK6cq8eRD4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as sk\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "       # return the mean squared error\n",
        "       return sk.mean_squared_error(y_true, y_pred)\n",
        "      #  return (1/y_true.shape[0])*np.sum(np.square(y_true-y_pred), axis=0)\n",
        "      #  pass  # Uncomment this when you're done with this function\n",
        "\n",
        "\n",
        "def r2_score(y_true, y_pred):\n",
        "      # return the r2 score\n",
        "      return sk.r2_score(y_true, y_pred)\n",
        "      # pass  # Uncomment this when you're done with this function\n",
        "          \n",
        "\n",
        "mse = mean_squared_error(predictions, y_test) # Pass appropriate parts of dataset\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "accu = r2_score(predictions, y_test) # Pass appropriate parts of dataset\n",
        "print(\"Accuracy:\", accu)"
      ],
      "metadata": {
        "id": "WqkrvDzcRF5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7942308-e305-44cb-c807-881cfe934157"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 391.0960196890423\n",
            "Accuracy: 0.9606065973728906\n"
          ]
        }
      ]
    }
  ]
}